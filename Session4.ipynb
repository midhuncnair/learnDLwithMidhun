{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5983a860",
   "metadata": {},
   "source": [
    "ContentBy: Midhun Chandran <learnwithmidhuncnair@gmail.com>\n",
    "License: Feel free to copy, edit, enhance and share.\n",
    "GitHub: https://github.com/midhuncnair/learnDLwithMidhun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ca589",
   "metadata": {},
   "source": [
    "# Advanced Computer Vision Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b211c5ab",
   "metadata": {},
   "source": [
    "## Session4: Object Detection (3 hours)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3a5b46d",
   "metadata": {},
   "source": [
    "Topics:\n",
    "        - Introduction to object localization\n",
    "        - Transfer learning for computer vision\n",
    "        - Hands-on: Implementing object localization\n",
    "        - Object Localization vs Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet import (\n",
    "    MobileNet, preprocess_input,\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    img_to_array, load_img,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from plot_layers import (\n",
    "    plot_layer_outputs, imshow, apply_patch,\n",
    "    IoU_metric,\n",
    ")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = os.path.join(os.path.abspath(''), 'data', 'images', 'localization', 'pets')\n",
    "# Ref: https://www.robots.ox.ac.uk/~vgg/data/pets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ec2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (128, 128)\n",
    "# image name and the object bounding box informations\n",
    "TRAIN_DATA_DF = pd.read_csv(os.path.join(LOCAL_DATA_PATH, 'train.csv'), header=None)\n",
    "TEST_DATA_DF = pd.read_csv(os.path.join(LOCAL_DATA_PATH, 'test.csv'), header=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "075115b5",
   "metadata": {},
   "source": [
    "The CSV contains the following columns:\n",
    "0 -> Path of the file from images folder\n",
    "1 -> height of the image\n",
    "2 -> width of the image\n",
    "3 -> x0 according to column 1, 2\n",
    "4 -> y0 according to column 1, 2\n",
    "5 -> x1 according to column 1, 2\n",
    "6 -> y1 according to column 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266abfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = ['ImagePath', 'Height', 'Width', 'X0', 'Y0', 'X1', 'Y1', 'Breed', 'BreedCategory']\n",
    "TRAIN_DATA_DF.columns = HEADER\n",
    "TEST_DATA_DF.columns = HEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f034db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_y(df_inp):\n",
    "    global TARGET_SIZE\n",
    "    df_out = pd.DataFrame()\n",
    "    # compute the y data for the target size\n",
    "    df_out['X0'] = (df_inp['X0'] /  df_inp['Width']) * TARGET_SIZE[0]\n",
    "    df_out['Y0'] = (df_inp['Y0'] /  df_inp['Height']) * TARGET_SIZE[1]\n",
    "\n",
    "    df_out['Width'] = ((df_inp['X1'] - df_inp['X0']) / df_inp['Width']) * TARGET_SIZE[0]\n",
    "    df_out['Height'] = ((df_inp['Y1'] - df_inp['Y0']) / df_inp['Height']) * TARGET_SIZE[1]\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute the y train data for the target size\n",
    "# Y_TRAIN_DF['X0'] = (TRAIN_DATA_DF['X0'] /  TRAIN_DATA_DF['Width']) * TARGET_SIZE[0]\n",
    "# Y_TRAIN_DF['Y0'] = (TRAIN_DATA_DF['X0'] /  TRAIN_DATA_DF['Height']) * TARGET_SIZE[1]\n",
    "\n",
    "# Y_TRAIN_DF['Width'] = ((TRAIN_DATA_DF['X1'] - TRAIN_DATA_DF['X0']) / TRAIN_DATA_DF['Width']) * TARGET_SIZE[0]\n",
    "# Y_TRAIN_DF['Height'] = ((TRAIN_DATA_DF['Y1'] - TRAIN_DATA_DF['Y0']) / TRAIN_DATA_DF['Height']) * TARGET_SIZE[1]\n",
    "Y_TRAIN_DF = compute_y(TRAIN_DATA_DF)\n",
    "Y_TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82787740",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TEST_DF = compute_y(TEST_DATA_DF)\n",
    "Y_TEST_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y_TRAIN_DF.to_numpy()\n",
    "y_test = Y_TEST_DF.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load x_train and x_test\n",
    "x_train = TRAIN_DATA_DF['ImagePath'].apply(lambda x: os.path.join(LOCAL_DATA_PATH, *x.split('/'))).to_numpy()\n",
    "x_test = TEST_DATA_DF['ImagePath'].apply(lambda x: os.path.join(LOCAL_DATA_PATH, *x.split('/'))).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85518def",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_files(paths):\n",
    "    count = 0\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            continue\n",
    "        count += 1\n",
    "        \n",
    "    print(f\"{count}/{len(paths)} missing\")\n",
    "has_files(x_train)\n",
    "has_files(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c63f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LOCATION = 100\n",
    "path = x_train[SAMPLE_LOCATION]\n",
    "img = cv2.imread(x_train[SAMPLE_LOCATION])\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_x0 = TRAIN_DATA_DF['X0'][SAMPLE_LOCATION]\n",
    "bb_y0 = TRAIN_DATA_DF['Y0'][SAMPLE_LOCATION]\n",
    "bb_x1 = TRAIN_DATA_DF['X1'][SAMPLE_LOCATION]\n",
    "bb_y1 = TRAIN_DATA_DF['Y1'][SAMPLE_LOCATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc43edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_x0, bb_y0, bb_x1, bb_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_patch(img, bb_x0, bb_y0, bb_x1, bb_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_for_model(paths):\n",
    "    out = []\n",
    "    for path in paths:\n",
    "        img = load_img(path, target_size=TARGET_SIZE)\n",
    "        img_arr = img_to_array(img)\n",
    "        out.append(preprocess_input(img_arr))\n",
    "        \n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_images_for_model(x_train)\n",
    "x_test = preprocess_images_for_model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2306dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 1.0 # Width hyper parameter for MobileNet (0.25, 0.5, 0.75, 1.0).\n",
    "\n",
    "def create_transfer_model_from_mobilenet(alpha, is_trainable=False):\n",
    "    global TARGET_SIZE\n",
    "    model = MobileNet(\n",
    "        input_shape=(*TARGET_SIZE, 3), \n",
    "        include_top=False,  # Do not include classification/top layer\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = is_trainable # freeze/unfreeze the pretrained layers.\n",
    "    \n",
    "    previous_layer = model.layers[-1]\n",
    "\n",
    "    custom_layer1 = Conv2D(4, kernel_size=4)(previous_layer.output)\n",
    "    output_layer = Reshape((4,))(custom_layer1)  # output size is 4.\n",
    "\n",
    "    return Model(inputs=model.input, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_transfer_model_from_mobilenet(alpha=ALPHA, is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c020fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"mean_squared_error\", # Regression loss is MSE\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy', IoU_metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='accuracy', patience=5, min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea2d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=5, batch_size=32,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f347d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    images = {\n",
    "        'samoyed_174.jpg',\n",
    "        'shiba_inu_163.jpg',\n",
    "        'Abyssinian_14.jpg',\n",
    "    }\n",
    "    for image in images:\n",
    "        image_file = os.path.join(LOCAL_DATA_PATH, 'images', image)\n",
    "        img = load_img(image_file, target_size=TARGET_SIZE)\n",
    "        img_array = img_to_array(img)\n",
    "        preds = model.predict(np.expand_dims(img_array, axis=0))[0]\n",
    "        img = cv2.imread(image_file)\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "        x0 = int(preds[0] * width / TARGET_SIZE[0])\n",
    "        y0 = int(preds[1] * height / TARGET_SIZE[1])\n",
    "\n",
    "        x1 = int((preds[0] + preds[2]) * width / TARGET_SIZE[0])\n",
    "        y1 = int((preds[1] + preds[3]) * height / TARGET_SIZE[1])\n",
    "        apply_patch(img, x0, y0, x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49255152",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3bd5d18",
   "metadata": {},
   "source": [
    "Ref: https://github.com/lukas/ml-class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
